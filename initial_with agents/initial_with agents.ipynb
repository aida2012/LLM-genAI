{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1- Cargar API KEY de PINECONE\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Cargar las variables del archivo .env\n",
    "load_dotenv()\n",
    "\n",
    "# Acceder a las claves\n",
    "PINECONE_API_KEY= os.getenv(\"BD_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (3.3.1)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.46.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (2.5.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.5.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (1.13.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (0.26.3)\n",
      "Requirement already satisfied: Pillow in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.14.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.10.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (75.6.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tqdm->sentence-transformers) (0.4.6)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (1.26.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.5.15)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.4.5)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2024.2.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# 2- Impmortar las librerias necesarias\n",
    "!pip install sentence-transformers\n",
    "from pinecone import Pinecone,ServerlessSpec,Index\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\anben\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (5.1.0)\n",
      "c:\\Users\\anben\\Desktop\\posgrado\\LLM-genAI\\initial_with agents\\..\\resume_Aida Benito.pdf\n"
     ]
    }
   ],
   "source": [
    "# 3- Cargar los archivos PDF\n",
    "!pip install pypdf\n",
    "def read_doc(directory):\n",
    "     file_loader=PyPDFLoader(directory)\n",
    "     documents = file_loader.load()\n",
    "     return documents\n",
    "\n",
    "\n",
    "current_directory = os.getcwd()\n",
    "dir_cv_aida = os.path.join(current_directory,'..', 'resume_Aida Benito.pdf')\n",
    "doc_aida=read_doc(dir_cv_aida)\n",
    "\n",
    "dir_cv_marcelo = os.path.join(current_directory,'..', 'CV_Pasut Marcelo.pdf')\n",
    "doc_marcelo=read_doc(dir_cv_marcelo)\n",
    "\n",
    "print (dir_cv_aida)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Primeros 2 fragmentos de doc_aida: [Document(page_content='AÍDABENITO\\nanbenito@yahoo.com.ar\\nQuilmes, BuenosAires, Argentina\\nCell: (54911)6-497-6858-Skype: anbenito1975@gmail.com\\nLinkedIn:https://www.linkedin.com/in/aida-benito/\\nINFORMATIONSYSTEMSENGINEER\\nExperiencedDataEngineer andBusiness IntelligenceConsultant. Possessesadvancedknowledgeof\\ndatabases and various BI tools, as well as knowledge of programming languages, AWS and GCP\\nEcosystems. Has strong communication skills. Passionate about Data Science, BigData, Internet of', metadata={'source': 'c:\\\\Users\\\\anben\\\\Desktop\\\\posgrado\\\\LLM-genAI\\\\initial_with agents\\\\..\\\\resume_Aida Benito.pdf', 'page': 0}), Document(page_content='Things, Artificial Intelligence, research and learning. Able to handle several projects simultaneously.\\nHaspassedtheFirst CertificateinEnglishexam.\\nCorecompetenciesinclude:\\nFlexibility-Leadership-Teamwork-Conflict resolution-Analytical thinking-Decisionmaking\\nCustomerService-Creativethinking\\nPROFESSIONALEXPERIENCE\\nMPSGroup-Client: DeltaAirlines\\n● Designandproposearchitecturesolutions\\n● DevelopETLcomponents\\n● DevelopSQLqueries', metadata={'source': 'c:\\\\Users\\\\anben\\\\Desktop\\\\posgrado\\\\LLM-genAI\\\\initial_with agents\\\\..\\\\resume_Aida Benito.pdf', 'page': 0})]\n",
      "Primeros 2 fragmentos de doc_marcelo: [Document(page_content='Perfil Profesional\\nSr. Pasut Marcelo Alejandro, de 41 años de edad, es un especialista en IT con experiencia en desarrollo y \\nanálisis de aplicaciones orientadas a objetos.\\nTiene conocimiento técnico en J2EE, WebSphere, DB2, Unix/Linux, Networking y XML.\\nSr. Pasut tiene cuatro años de experiencia en trabajo con sistemas operativos como Linux, Unix, MS-DOS y \\nWindows. También maneja una cierta cantidad de herramientas para esos lenguajes.', metadata={'source': 'c:\\\\Users\\\\anben\\\\Desktop\\\\posgrado\\\\LLM-genAI\\\\initial_with agents\\\\..\\\\CV_Pasut Marcelo.pdf', 'page': 0}), Document(page_content='A partir de Marzo del 2005 paso a ser miembro de un equipo de IBM que desarrolla mejoras y tareas de \\nmantenimientos para una aplicación de proceso de negocio que maneja alto volumen de datos con poca \\nintervención humana.\\nDesde Octubre del 2005 fue miembro de un equipo que desarrolla mejoras y tareas de mantenimiento para \\nuna aplicación de procesos de negocio y administración de recursos humanos. La aplicación tiene una', metadata={'source': 'c:\\\\Users\\\\anben\\\\Desktop\\\\posgrado\\\\LLM-genAI\\\\initial_with agents\\\\..\\\\CV_Pasut Marcelo.pdf', 'page': 0})]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Dividir el documento en fragmentos pequeños\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "split_doc_aida = text_splitter.split_documents(doc_aida)\n",
    "split_doc_marcelo = text_splitter.split_documents(doc_marcelo)\n",
    "\n",
    "# Ver los primeros fragmentos para asegurar que la división fue correcta\n",
    "print(f\"Primeros 2 fragmentos de doc_aida: {split_doc_aida[:2]}\")\n",
    "print(f\"Primeros 2 fragmentos de doc_marcelo: {split_doc_marcelo[:2]}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index resume-index-aida borrado\n",
      "index resume-index-marcelo borrado\n",
      "index_aida: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n",
      "index_marcelo: {'dimension': 384,\n",
      " 'index_fullness': 0.0,\n",
      " 'namespaces': {},\n",
      " 'total_vector_count': 0}\n"
     ]
    }
   ],
   "source": [
    "# 4- Inicializar Pinecone\n",
    "from pinecone import ServerlessSpec\n",
    "import time\n",
    "pc=Pinecone(api_key=PINECONE_API_KEY)\n",
    "cloud = 'aws'\n",
    "region = 'us-east-1'\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)\n",
    "\n",
    "\n",
    "\n",
    "index_name1 = \"resume-index-aida\"\n",
    "index_name2 = \"resume-index-marcelo\"\n",
    "\n",
    "\n",
    "def delete_if_exists(index_name,pc):\n",
    "   if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "    print(\"index {} borrado\".format(index_name))\n",
    "\n",
    "    time.sleep(1)\n",
    "\n",
    "delete_if_exists(index_name1,pc)\n",
    "delete_if_exists(index_name2,pc)\n",
    "\n",
    "# Si el índice no existe, lo creamos\n",
    "\n",
    "def create_index(index_name,pc):\n",
    "  if index_name not in pc.list_indexes().names():\n",
    "      pc.create_index(\n",
    "          index_name,\n",
    "          dimension=384,  \n",
    "          metric='cosine',\n",
    "          spec=spec)\n",
    "\n",
    "create_index(index_name1,pc)\n",
    "create_index(index_name2,pc)\n",
    "\n",
    "# connect to index\n",
    "index_aida = pc.Index(index_name1)\n",
    "index_marcelo = pc.Index(index_name2)\n",
    "time.sleep(1)\n",
    "\n",
    "# view index stats\n",
    "print(\"index_aida: {}\".format(index_aida.describe_index_stats()))\n",
    "print(\"index_marcelo: {}\".format(index_marcelo.describe_index_stats()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings generados y almacenados en el índice 'resume-index-aida' de Pinecone.\n",
      "Embeddings generados y almacenados en el índice 'resume-index-marcelo' de Pinecone.\n"
     ]
    }
   ],
   "source": [
    "embed_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Generar embeddings usando el modelo \n",
    "\n",
    "\n",
    "texts_aida = [doc.page_content for doc in split_doc_aida]\n",
    "texts_marcelo = [doc.page_content for doc in split_doc_marcelo]\n",
    "aida_embeddings = embed_model.encode(texts_aida)\n",
    "marcelo_embeddings = embed_model.encode(texts_marcelo)\n",
    "\n",
    "\n",
    "def upsert_embeddings(embeddings,index_name,index,texts,name):\n",
    "    upsert_data_generator = [\n",
    "        {\n",
    "            'id': str(i), \n",
    "            'values': embedding, \n",
    "            'metadata': {'text': texts[i], 'persona': name}\n",
    "        }\n",
    "        for i, embedding in enumerate(embeddings)\n",
    "    ]\n",
    "    index.upsert(vectors=upsert_data_generator)\n",
    "    print(f\"Embeddings generados y almacenados en el índice '{index_name}' de Pinecone.\")\n",
    "\n",
    "upsert_embeddings(aida_embeddings,index_name1,index_aida,texts_aida,\"Aida\")\n",
    "upsert_embeddings(marcelo_embeddings,index_name2,index_marcelo,texts_marcelo,\"Marcelo\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
